{"cells":[{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# In Assignment-4 when we fit our model on smaller dataset, we saw that Global Meam model won over Item to Item collaborative filtering\n# In this exercise we will use PySpark and distributed computing environment to fit the model on entire data set and see if Item-Item collaborative filtering works"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#### In this assigmnment we will build two recommender systems and access their performance\n#- Recomendation based on global mean and user/movie bias\n#- Recommendation based on Item-Item collaborative filtering\n#### We will use training set to build a recommender system and evaluate it's performance on the test set. We will use MSE (mean square error) as a measure of model efficiency. Model wil low RMSE will win over model with higher MSE"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# Import required libraries"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math\nfrom scipy.spatial.distance import cosine\nfrom functools import reduce\nimport pyspark.sql.types as types\nfrom pyspark.sql.functions import *\nfrom pyspark.mllib.linalg import Matrix, Matrices"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Read the input data\n\n##### In this assignment we will use MovieLens dataset. It has been collected by the GroupLens Research Project at the University of Minnesota. It consists of:\n\n# - 100,000 ratings (1-5) from 943 users on 1682 movies.\n# - Each user has rated at least 20 movies.\n# - Simple demographic info for the users (age, gender, occupation, zip)\n# - Genre information of movies"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#Reading ratings file:\nschema = types.StructType([\n    types.StructField(\"userid\", types.IntegerType()),\n    types.StructField(\"movieid\", types.IntegerType()),\n    types.StructField(\"rating\", types.IntegerType()),\n    types.StructField(\"unixtimestamp\", types.DateType())\n])\ntrain = spark.read.csv('/mnt/data/forsachid/ua.base', sep='\\t', header=True, schema=schema)\ntest = spark.read.csv('/mnt/data/forsachid/ua.test', sep='\\t' , header=True, schema=schema)\nglobalmean = np.mean(train.select('rating').collect())\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["#### Model-1 Recommendation based on global mean, user bias and movie bias\n#### Calculate global mean, userbias and movie bias"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["userbias =  spark.createDataFrame(train.groupby('userid').mean().collect())\nuserbias = userbias[['userid', 'avg(rating)']].withColumnRenamed('avg(rating)', 'rating')\nuserbias = userbias.withColumn('newrating', userbias.rating - globalmean ).drop('rating').withColumnRenamed('newrating', 'userbias')\n\nmoviebias =  spark.createDataFrame(train.groupby('movieid').mean().collect())\nmoviebias = moviebias[['movieid', 'avg(rating)']].withColumnRenamed('avg(rating)', 'rating')\nmoviebias = moviebias.withColumn('newrating', moviebias.rating - globalmean ).drop('rating').withColumnRenamed('newrating', 'moviebias')\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["# We can see the MSE for global mean model is 1.24"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["testjoin = test.join(userbias, test.userid == userbias.userid, 'left_outer').select(test.userid, test.movieid, test.rating, userbias.userbias)\ntestjoin = testjoin.join(moviebias, testjoin.movieid == moviebias.movieid, 'left_outer').select(testjoin.userid, testjoin.movieid, testjoin.rating, testjoin.userbias, moviebias.moviebias)\ntestjoin = testjoin.withColumn('recc_rating', globalmean + testjoin.userbias + testjoin.moviebias)\ntestjoin = testjoin.fillna(0)\nratarray = np.array(testjoin.select('rating').collect()).astype(float)\nreccratarray = np.array(testjoin.select('recc_rating').collect()).astype(float)\nmse = np.mean(((ratarray-reccratarray)**2))\nprint(mse)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">1.23167458591\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["#Use pyspark.mllip.recommendation library to make recommendation"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["train = train.drop('unixtimestamp')\ntest = test.drop('unixtimestamp')\n\nfrom pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\ntrainratings = train.rdd.map(lambda r: Rating((r[0]), (r[1]), (r[2])))\n#Build the recommendation model using Alternating Least Squares\nrank = 50\nnumIterations = 20\nmodel = ALS.train(trainratings, rank, numIterations)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["# MAke recommendations on test set. We can see that MSE for Item to Item collaborative filtering model is 1.42"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["testratings = test.rdd.map(lambda r: Rating(int(r[0]), int(r[1]), float(r[2])))\ntestdata = testratings.map(lambda p: (p[0], p[1]))\npredictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))\nratesAndPreds = testratings.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\nMSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\nprint(\"Mean Squared Error = \" + str(MSE))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Mean Squared Error = 1.424215073163655\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["# Conclusion - We can see that global mean model is still outperforming Item to Item collaborative filtering model even when we fit our model on entire dataset. This is very interesting result. We can tweak the Item to Item collaborative filtering model parameters even further to improve the accuracy of the model. For now we will conclude our experiment with the fact that global mean model with user bias and movie bias factored in is also a very powerful model. Complex models lile content based recommendation and collaborative filtering based models needs to fine tuned in order for them to excel global mean based model"],"metadata":{},"outputs":[],"execution_count":16}],"metadata":{"name":"Recommender Systems","notebookId":2076357415155799},"nbformat":4,"nbformat_minor":0}
